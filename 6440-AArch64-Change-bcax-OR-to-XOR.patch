From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Sleigh-InSPECtor <sleighinspector@outlook.com>
Date: Thu, 18 Apr 2024 16:12:08 +0930
Subject: [PATCH] 6440: AArch64: Change bcax OR to XOR

AA64: Change bcax OR to XOR
---
 .../AARCH64/data/languages/AARCH64neon.sinc   | 34 +++++++++----------
 1 file changed, 17 insertions(+), 17 deletions(-)

diff --git a/Ghidra/Processors/AARCH64/data/languages/AARCH64neon.sinc b/Ghidra/Processors/AARCH64/data/languages/AARCH64neon.sinc
index a3f4bdb003..b73058f7d2 100644
--- a/Ghidra/Processors/AARCH64/data/languages/AARCH64neon.sinc
+++ b/Ghidra/Processors/AARCH64/data/languages/AARCH64neon.sinc
@@ -938,23 +938,23 @@ is b_2131=0b11001110001 & b_15=0 & Rd_VPR128.16B & Rn_VPR128.16B & Rm_VPR128.16B
 	TMPQ2[104,8] = Rm_VPR128.16B[104,8] & TMPQ1[104,8];
 	TMPQ2[112,8] = Rm_VPR128.16B[112,8] & TMPQ1[112,8];
 	TMPQ2[120,8] = Rm_VPR128.16B[120,8] & TMPQ1[120,8];
-	# simd infix Rd_VPR128.16B = Rn_VPR128.16B | TMPQ2 on lane size 1
-	Rd_VPR128.16B[0,8] = Rn_VPR128.16B[0,8] | TMPQ2[0,8];
-	Rd_VPR128.16B[8,8] = Rn_VPR128.16B[8,8] | TMPQ2[8,8];
-	Rd_VPR128.16B[16,8] = Rn_VPR128.16B[16,8] | TMPQ2[16,8];
-	Rd_VPR128.16B[24,8] = Rn_VPR128.16B[24,8] | TMPQ2[24,8];
-	Rd_VPR128.16B[32,8] = Rn_VPR128.16B[32,8] | TMPQ2[32,8];
-	Rd_VPR128.16B[40,8] = Rn_VPR128.16B[40,8] | TMPQ2[40,8];
-	Rd_VPR128.16B[48,8] = Rn_VPR128.16B[48,8] | TMPQ2[48,8];
-	Rd_VPR128.16B[56,8] = Rn_VPR128.16B[56,8] | TMPQ2[56,8];
-	Rd_VPR128.16B[64,8] = Rn_VPR128.16B[64,8] | TMPQ2[64,8];
-	Rd_VPR128.16B[72,8] = Rn_VPR128.16B[72,8] | TMPQ2[72,8];
-	Rd_VPR128.16B[80,8] = Rn_VPR128.16B[80,8] | TMPQ2[80,8];
-	Rd_VPR128.16B[88,8] = Rn_VPR128.16B[88,8] | TMPQ2[88,8];
-	Rd_VPR128.16B[96,8] = Rn_VPR128.16B[96,8] | TMPQ2[96,8];
-	Rd_VPR128.16B[104,8] = Rn_VPR128.16B[104,8] | TMPQ2[104,8];
-	Rd_VPR128.16B[112,8] = Rn_VPR128.16B[112,8] | TMPQ2[112,8];
-	Rd_VPR128.16B[120,8] = Rn_VPR128.16B[120,8] | TMPQ2[120,8];
+	# simd infix Rd_VPR128.16B = Rn_VPR128.16B ^ TMPQ2 on lane size 1
+	Rd_VPR128.16B[0,8] = Rn_VPR128.16B[0,8] ^ TMPQ2[0,8];
+	Rd_VPR128.16B[8,8] = Rn_VPR128.16B[8,8] ^ TMPQ2[8,8];
+	Rd_VPR128.16B[16,8] = Rn_VPR128.16B[16,8] ^ TMPQ2[16,8];
+	Rd_VPR128.16B[24,8] = Rn_VPR128.16B[24,8] ^ TMPQ2[24,8];
+	Rd_VPR128.16B[32,8] = Rn_VPR128.16B[32,8] ^ TMPQ2[32,8];
+	Rd_VPR128.16B[40,8] = Rn_VPR128.16B[40,8] ^ TMPQ2[40,8];
+	Rd_VPR128.16B[48,8] = Rn_VPR128.16B[48,8] ^ TMPQ2[48,8];
+	Rd_VPR128.16B[56,8] = Rn_VPR128.16B[56,8] ^ TMPQ2[56,8];
+	Rd_VPR128.16B[64,8] = Rn_VPR128.16B[64,8] ^ TMPQ2[64,8];
+	Rd_VPR128.16B[72,8] = Rn_VPR128.16B[72,8] ^ TMPQ2[72,8];
+	Rd_VPR128.16B[80,8] = Rn_VPR128.16B[80,8] ^ TMPQ2[80,8];
+	Rd_VPR128.16B[88,8] = Rn_VPR128.16B[88,8] ^ TMPQ2[88,8];
+	Rd_VPR128.16B[96,8] = Rn_VPR128.16B[96,8] ^ TMPQ2[96,8];
+	Rd_VPR128.16B[104,8] = Rn_VPR128.16B[104,8] ^ TMPQ2[104,8];
+	Rd_VPR128.16B[112,8] = Rn_VPR128.16B[112,8] ^ TMPQ2[112,8];
+	Rd_VPR128.16B[120,8] = Rn_VPR128.16B[120,8] ^ TMPQ2[120,8];
 	zext_zq(Zd); # zero upper 16 bytes of Zd
 }
 
-- 
2.45.1

