From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Sleigh-InSPECtor <sleighinspector@outlook.com>
Date: Mon, 20 May 2024 12:41:11 +0930
Subject: [PATCH] 6543: AArch64: Fix fmla and fmls element count and size for
 halfword cases

AA64: Fix fmla and fmls elements for halfword case
---
 .../AARCH64/data/languages/AARCH64neon.sinc   | 72 ++++++++++++-------
 1 file changed, 48 insertions(+), 24 deletions(-)

diff --git a/Ghidra/Processors/AARCH64/data/languages/AARCH64neon.sinc b/Ghidra/Processors/AARCH64/data/languages/AARCH64neon.sinc
index a41991eb94..4a225f9eaf 100644
--- a/Ghidra/Processors/AARCH64/data/languages/AARCH64neon.sinc
+++ b/Ghidra/Processors/AARCH64/data/languages/AARCH64neon.sinc
@@ -7284,11 +7284,15 @@ is b_3131=0 & q=1 & u=0 & b_2428=0xe & advSIMD3.size=0 & b_2121=1 & Rm_VPR128.4S
 is b_31=0 & b_30=0 & b_2129=0b001110010 & b_1015=0b000011 & Rd_VPR64.4H & Rn_VPR64.4H & Rm_VPR64.4H & Zd
 {
 	# simd infix TMPD1 = Rn_VPR64.4H f* Rm_VPR64.4H on lane size 4
-	TMPD1[0,32] = Rn_VPR64.4H[0,32] f* Rm_VPR64.4H[0,32];
-	TMPD1[32,32] = Rn_VPR64.4H[32,32] f* Rm_VPR64.4H[32,32];
+	TMPD1[0,16] = Rn_VPR64.4H[0,16] f* Rm_VPR64.4H[0,16];
+	TMPD1[16,16] = Rn_VPR64.4H[16,16] f* Rm_VPR64.4H[16,16];
+	TMPD1[32,16] = Rn_VPR64.4H[32,16] f* Rm_VPR64.4H[32,16];
+	TMPD1[48,16] = Rn_VPR64.4H[48,16] f* Rm_VPR64.4H[48,16];
 	# simd infix Rd_VPR64.4H = Rd_VPR64.4H f+ TMPD1 on lane size 4
-	Rd_VPR64.4H[0,32] = Rd_VPR64.4H[0,32] f+ TMPD1[0,32];
-	Rd_VPR64.4H[32,32] = Rd_VPR64.4H[32,32] f+ TMPD1[32,32];
+	Rd_VPR64.4H[0,16] = Rd_VPR64.4H[0,16] f+ TMPD1[0,16];
+	Rd_VPR64.4H[16,16] = Rd_VPR64.4H[16,16] f+ TMPD1[16,16];
+	Rd_VPR64.4H[32,16] = Rd_VPR64.4H[32,16] f+ TMPD1[32,16];
+	Rd_VPR64.4H[48,16] = Rd_VPR64.4H[48,16] f+ TMPD1[48,16];
 	zext_zd(Zd); # zero upper 24 bytes of Zd
 }
 
@@ -7303,15 +7307,23 @@ is b_31=0 & b_30=0 & b_2129=0b001110010 & b_1015=0b000011 & Rd_VPR64.4H & Rn_VPR
 is b_31=0 & b_30=1 & b_2129=0b001110010 & b_1015=0b000011 & Rd_VPR128.8H & Rn_VPR128.8H & Rm_VPR128.8H & Zd
 {
 	# simd infix TMPQ1 = Rn_VPR128.8H f* Rm_VPR128.8H on lane size 4
-	TMPQ1[0,32] = Rn_VPR128.8H[0,32] f* Rm_VPR128.8H[0,32];
-	TMPQ1[32,32] = Rn_VPR128.8H[32,32] f* Rm_VPR128.8H[32,32];
-	TMPQ1[64,32] = Rn_VPR128.8H[64,32] f* Rm_VPR128.8H[64,32];
-	TMPQ1[96,32] = Rn_VPR128.8H[96,32] f* Rm_VPR128.8H[96,32];
+	TMPQ1[0,16] = Rn_VPR128.8H[0,16] f* Rm_VPR128.8H[0,16];
+	TMPQ1[16,16] = Rn_VPR128.8H[16,16] f* Rm_VPR128.8H[16,16];
+	TMPQ1[32,16] = Rn_VPR128.8H[32,16] f* Rm_VPR128.8H[32,16];
+	TMPQ1[48,16] = Rn_VPR128.8H[48,16] f* Rm_VPR128.8H[48,16];
+	TMPQ1[64,16] = Rn_VPR128.8H[64,16] f* Rm_VPR128.8H[64,16];
+	TMPQ1[80,16] = Rn_VPR128.8H[80,16] f* Rm_VPR128.8H[80,16];
+	TMPQ1[96,16] = Rn_VPR128.8H[96,16] f* Rm_VPR128.8H[96,16];
+	TMPQ1[112,16] = Rn_VPR128.8H[112,16] f* Rm_VPR128.8H[112,16];
 	# simd infix Rd_VPR128.8H = Rd_VPR128.8H f+ TMPQ1 on lane size 4
-	Rd_VPR128.8H[0,32] = Rd_VPR128.8H[0,32] f+ TMPQ1[0,32];
-	Rd_VPR128.8H[32,32] = Rd_VPR128.8H[32,32] f+ TMPQ1[32,32];
-	Rd_VPR128.8H[64,32] = Rd_VPR128.8H[64,32] f+ TMPQ1[64,32];
-	Rd_VPR128.8H[96,32] = Rd_VPR128.8H[96,32] f+ TMPQ1[96,32];
+	Rd_VPR128.8H[0,16] = Rd_VPR128.8H[0,16] f+ TMPQ1[0,16];
+	Rd_VPR128.8H[16,16] = Rd_VPR128.8H[16,16] f+ TMPQ1[16,16];
+	Rd_VPR128.8H[32,16] = Rd_VPR128.8H[32,16] f+ TMPQ1[32,16];
+	Rd_VPR128.8H[48,16] = Rd_VPR128.8H[48,16] f+ TMPQ1[48,16];
+	Rd_VPR128.8H[64,16] = Rd_VPR128.8H[64,16] f+ TMPQ1[64,16];
+	Rd_VPR128.8H[80,16] = Rd_VPR128.8H[80,16] f+ TMPQ1[80,16];
+	Rd_VPR128.8H[96,16] = Rd_VPR128.8H[96,16] f+ TMPQ1[96,16];
+	Rd_VPR128.8H[112,16] = Rd_VPR128.8H[112,16] f+ TMPQ1[112,16];
 	zext_zq(Zd); # zero upper 16 bytes of Zd
 }
 
@@ -7777,11 +7789,15 @@ is b_3131=0 & q=1 & u=0 & b_2428=0xe & advSIMD3.size=2 & b_2121=1 & Rm_VPR128.4S
 is b_31=0 & b_30=0 & b_2129=0b001110110 & b_1015=0b000011 & Rd_VPR64.4H & Rn_VPR64.4H & Rm_VPR64.4H & Zd
 {
 	# simd infix TMPD1 = Rn_VPR64.4H f* Rm_VPR64.4H on lane size 4
-	TMPD1[0,32] = Rn_VPR64.4H[0,32] f* Rm_VPR64.4H[0,32];
-	TMPD1[32,32] = Rn_VPR64.4H[32,32] f* Rm_VPR64.4H[32,32];
+	TMPD1[0,16] = Rn_VPR64.4H[0,16] f* Rm_VPR64.4H[0,16];
+	TMPD1[16,16] = Rn_VPR64.4H[16,16] f* Rm_VPR64.4H[16,16];
+	TMPD1[32,16] = Rn_VPR64.4H[32,16] f* Rm_VPR64.4H[32,16];
+	TMPD1[48,16] = Rn_VPR64.4H[48,16] f* Rm_VPR64.4H[48,16];
 	# simd infix Rd_VPR64.4H = Rd_VPR64.4H f- TMPD1 on lane size 4
-	Rd_VPR64.4H[0,32] = Rd_VPR64.4H[0,32] f- TMPD1[0,32];
-	Rd_VPR64.4H[32,32] = Rd_VPR64.4H[32,32] f- TMPD1[32,32];
+	Rd_VPR64.4H[0,16] = Rd_VPR64.4H[0,16] f- TMPD1[0,16];
+	Rd_VPR64.4H[16,16] = Rd_VPR64.4H[16,16] f- TMPD1[16,16];
+	Rd_VPR64.4H[32,16] = Rd_VPR64.4H[32,16] f- TMPD1[32,16];
+	Rd_VPR64.4H[48,16] = Rd_VPR64.4H[48,16] f- TMPD1[48,16];
 	zext_zd(Zd); # zero upper 24 bytes of Zd
 }
 
@@ -7796,15 +7812,23 @@ is b_31=0 & b_30=0 & b_2129=0b001110110 & b_1015=0b000011 & Rd_VPR64.4H & Rn_VPR
 is b_31=0 & b_30=1 & b_2129=0b001110110 & b_1015=0b000011 & Rd_VPR128.8H & Rn_VPR128.8H & Rm_VPR128.8H & Zd
 {
 	# simd infix TMPQ1 = Rn_VPR128.8H f* Rm_VPR128.8H on lane size 4
-	TMPQ1[0,32] = Rn_VPR128.8H[0,32] f* Rm_VPR128.8H[0,32];
-	TMPQ1[32,32] = Rn_VPR128.8H[32,32] f* Rm_VPR128.8H[32,32];
-	TMPQ1[64,32] = Rn_VPR128.8H[64,32] f* Rm_VPR128.8H[64,32];
-	TMPQ1[96,32] = Rn_VPR128.8H[96,32] f* Rm_VPR128.8H[96,32];
+	TMPQ1[0,16] = Rn_VPR128.8H[0,16] f* Rm_VPR128.8H[0,16];
+	TMPQ1[16,16] = Rn_VPR128.8H[16,16] f* Rm_VPR128.8H[16,16];
+	TMPQ1[32,16] = Rn_VPR128.8H[32,16] f* Rm_VPR128.8H[32,16];
+	TMPQ1[48,16] = Rn_VPR128.8H[48,16] f* Rm_VPR128.8H[48,16];
+	TMPQ1[64,16] = Rn_VPR128.8H[64,16] f* Rm_VPR128.8H[64,16];
+	TMPQ1[80,16] = Rn_VPR128.8H[80,16] f* Rm_VPR128.8H[80,16];
+	TMPQ1[96,16] = Rn_VPR128.8H[96,16] f* Rm_VPR128.8H[96,16];
+	TMPQ1[112,16] = Rn_VPR128.8H[112,16] f* Rm_VPR128.8H[112,16];
 	# simd infix Rd_VPR128.8H = Rd_VPR128.8H f- TMPQ1 on lane size 4
-	Rd_VPR128.8H[0,32] = Rd_VPR128.8H[0,32] f- TMPQ1[0,32];
-	Rd_VPR128.8H[32,32] = Rd_VPR128.8H[32,32] f- TMPQ1[32,32];
-	Rd_VPR128.8H[64,32] = Rd_VPR128.8H[64,32] f- TMPQ1[64,32];
-	Rd_VPR128.8H[96,32] = Rd_VPR128.8H[96,32] f- TMPQ1[96,32];
+	Rd_VPR128.8H[0,16] = Rd_VPR128.8H[0,16] f- TMPQ1[0,16];
+	Rd_VPR128.8H[16,16] = Rd_VPR128.8H[16,16] f- TMPQ1[16,16];
+	Rd_VPR128.8H[32,16] = Rd_VPR128.8H[32,16] f- TMPQ1[32,16];
+	Rd_VPR128.8H[48,16] = Rd_VPR128.8H[48,16] f- TMPQ1[48,16];
+	Rd_VPR128.8H[64,16] = Rd_VPR128.8H[64,16] f- TMPQ1[64,16];
+	Rd_VPR128.8H[80,16] = Rd_VPR128.8H[80,16] f- TMPQ1[80,16];
+	Rd_VPR128.8H[96,16] = Rd_VPR128.8H[96,16] f- TMPQ1[96,16];
+	Rd_VPR128.8H[112,16] = Rd_VPR128.8H[112,16] f- TMPQ1[112,16];
 	zext_zq(Zd); # zero upper 16 bytes of Zd
 }
 
-- 
2.45.1

