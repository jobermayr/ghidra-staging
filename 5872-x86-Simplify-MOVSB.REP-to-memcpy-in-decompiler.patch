From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Johannes Obermayr <johannesobermayr@gmx.de>
Date: Tue, 10 Oct 2023 19:05:17 +0200
Subject: [PATCH] 5872: x86: Simplify MOVSB.REP to memcpy in decompiler

---
 Ghidra/Processors/x86/data/languages/ia.sinc  | 298 ++++++++++++++++--
 .../x86/data/languages/lockable.sinc          |  51 ++-
 2 files changed, 316 insertions(+), 33 deletions(-)

diff --git a/Ghidra/Processors/x86/data/languages/ia.sinc b/Ghidra/Processors/x86/data/languages/ia.sinc
index 05751cb074..fb873ec900 100644
--- a/Ghidra/Processors/x86/data/languages/ia.sinc
+++ b/Ghidra/Processors/x86/data/languages/ia.sinc
@@ -1448,25 +1448,25 @@ moffs64: segWide^[imm32]  is addrsize=1 & highseg=1 & segWide & imm32   { tmp:8
 # TODO: segment register offset in 64bit might not be right
 
 # String memory access
-dseSI1: seg16^SI    is addrsize=0 & seg16 & SI  { tmp:4 = segment(seg16,SI); SI = SI + 1-2*zext(DF); export *:1 tmp; }
-dseSI1: segWide^ESI   is addrsize=1 & segWide & ESI { tmp:4 = ESI; ESI = ESI + 1-2*zext(DF); export *:1 tmp; }
-dseSI2: seg16^SI    is addrsize=0 & seg16 & SI  { tmp:4 = segment(seg16,SI); SI = SI + 2-4*zext(DF); export *:2 tmp; }
-dseSI2: segWide^ESI   is addrsize=1 & segWide & ESI { tmp:4 = ESI; ESI = ESI + 2-4*zext(DF); export *:2 tmp; }
-dseSI4: seg16^SI    is addrsize=0 & seg16 & SI  { tmp:4 = segment(seg16,SI); SI = SI + 4-8*zext(DF); export *:4 tmp; }
-dseSI4: segWide^ESI   is addrsize=1 & segWide & ESI { tmp:4 = ESI; ESI = ESI + 4-8*zext(DF); export *:4 tmp; }
-eseDI1: ES:DI       is addrsize=0 & ES & DI     { tmp:4 = segment(ES,DI); DI = DI + 1-2*zext(DF); export *:1 tmp; }
-eseDI1: ES:EDI      is addrsize=1 & ES & EDI    { tmp:4 = EDI; EDI=EDI+1-2*zext(DF); export *:1 tmp; }
-eseDI2: ES:DI       is addrsize=0 & ES & DI     { tmp:4 = segment(ES,DI); DI = DI + 2-4*zext(DF); export *:2 tmp; }
-eseDI2: ES:EDI      is addrsize=1 & ES & EDI    { tmp:4 = EDI; EDI=EDI+2-4*zext(DF); export *:2 tmp; }
-eseDI4: ES:DI       is addrsize=0 & ES & DI     { tmp:4 = segment(ES,DI); DI = DI + 4-8*zext(DF); export *:4 tmp; }
-eseDI4: ES:EDI      is addrsize=1 & ES & EDI    { tmp:4 = EDI; EDI=EDI+4-8*zext(DF); export *:4 tmp; }
+pdseSI1: seg16^SI    is addrsize=0 & seg16 & SI  { tmp:4 = segment(seg16,SI); SI = SI + 1-2*zext(DF); export tmp; }
+pdseSI1: segWide^ESI   is addrsize=1 & segWide & ESI { tmp:4 = ESI; ESI = ESI + 1-2*zext(DF); export tmp; }
+pdseSI2: seg16^SI    is addrsize=0 & seg16 & SI  { tmp:4 = segment(seg16,SI); SI = SI + 2-4*zext(DF); export tmp; }
+pdseSI2: segWide^ESI   is addrsize=1 & segWide & ESI { tmp:4 = ESI; ESI = ESI + 2-4*zext(DF); export tmp; }
+pdseSI4: seg16^SI    is addrsize=0 & seg16 & SI  { tmp:4 = segment(seg16,SI); SI = SI + 4-8*zext(DF); export tmp; }
+pdseSI4: segWide^ESI   is addrsize=1 & segWide & ESI { tmp:4 = ESI; ESI = ESI + 4-8*zext(DF); export tmp; }
+peseDI1: ES:DI       is addrsize=0 & ES & DI     { tmp:4 = segment(ES,DI); DI = DI + 1-2*zext(DF); export tmp; }
+peseDI1: ES:EDI      is addrsize=1 & ES & EDI    { tmp:4 = EDI; EDI=EDI+1-2*zext(DF); export tmp; }
+peseDI2: ES:DI       is addrsize=0 & ES & DI     { tmp:4 = segment(ES,DI); DI = DI + 2-4*zext(DF); export tmp; }
+peseDI2: ES:EDI      is addrsize=1 & ES & EDI    { tmp:4 = EDI; EDI=EDI+2-4*zext(DF); export tmp; }
+peseDI4: ES:DI       is addrsize=0 & ES & DI     { tmp:4 = segment(ES,DI); DI = DI + 4-8*zext(DF); export tmp; }
+peseDI4: ES:EDI      is addrsize=1 & ES & EDI    { tmp:4 = EDI; EDI=EDI+4-8*zext(DF); export tmp; }
 
 @ifdef IA64
 # quadword string functions
-dseSI8: seg16^SI    is addrsize=0 & seg16 & SI  { tmp:4 = segment(seg16,SI); SI = SI + 8-16*zext(DF); export *:8 tmp; }
-dseSI8: segWide^ESI   is addrsize=1 & segWide & ESI { tmp:4 = ESI; ESI = ESI + 8-16*zext(DF); export *:8 tmp; }
-eseDI8: ES:DI       is addrsize=0 & ES & DI     { tmp:4 = segment(ES,DI); DI = DI + 8-16*zext(DF); export *:8 tmp; }
-eseDI8: ES:EDI      is addrsize=1 & ES & EDI    { tmp:4 = EDI; EDI=EDI+8-16*zext(DF); export *:8 tmp; }
+pdseSI8: seg16^SI    is addrsize=0 & seg16 & SI  { tmp:4 = segment(seg16,SI); SI = SI + 8-16*zext(DF); export tmp; }
+pdseSI8: segWide^ESI   is addrsize=1 & segWide & ESI { tmp:4 = ESI; ESI = ESI + 8-16*zext(DF); export tmp; }
+peseDI8: ES:DI       is addrsize=0 & ES & DI     { tmp:4 = segment(ES,DI); DI = DI + 8-16*zext(DF); export tmp; }
+peseDI8: ES:EDI      is addrsize=1 & ES & EDI    { tmp:4 = EDI; EDI=EDI+8-16*zext(DF); export tmp; }
 
 dseSI1: RSI   is addrsize=2 & RSI { local tmp = RSI; RSI = RSI + 1-2*zext(DF); export *:1 tmp; }
 dseSI2: RSI   is addrsize=2 & RSI { local tmp = RSI; RSI = RSI + 2-4*zext(DF); export *:2 tmp; }
@@ -1478,6 +1478,17 @@ eseDI4: RDI   is addrsize=2 & RDI    { local tmp = RDI; RDI=RDI+4-8*zext(DF); ex
 eseDI8: RDI   is addrsize=2 & RDI    { local tmp = RDI; RDI=RDI+8-16*zext(DF); export *:8 tmp; }
 @endif
 
+dseSI1: pdseSI1 is pdseSI1 { export *:1 pdseSI1; }
+dseSI2: pdseSI2 is pdseSI2 { export *:2 pdseSI2; }
+dseSI4: pdseSI4 is pdseSI4 { export *:4 pdseSI4; }
+eseDI1: peseDI1 is peseDI1 { export *:1 peseDI1; }
+eseDI2: peseDI2 is peseDI2 { export *:2 peseDI2; }
+eseDI4: peseDI4 is peseDI4 { export *:4 peseDI4; }
+@ifdef IA64
+dseSI8: pdseSI8 is pdseSI8 { export *:8 pdseSI8; }
+eseDI8: peseDI8 is peseDI8 { export *:8 peseDI8; }
+@endif
+
 rm8: Rmr8   is mod=3 & Rmr8     { export Rmr8; }
 rm8: "byte ptr" Mem    is  Mem             { export *:1 Mem; }
 
@@ -1550,6 +1561,8 @@ rep: ".REP" is ((repprefx=1 & repneprefx=0)|(repprefx=0 & repneprefx=1)) & addrs
 rep: ".REP" is ((repprefx=1 & repneprefx=0)|(repprefx=0 & repneprefx=1)) & addrsize=2  { if (RCX==0) goto inst_next; RCX=RCX-1; }
 @endif
 rep:        is repprefx=0 & repneprefx=0			{ }
+repx: ".REP" is ((repprefx=1 & repneprefx=0)|(repprefx=0 & repneprefx=1)) { }
+repx:        is repprefx=0 & repneprefx=0			{ }
 
 reptail:	is ((repprefx=1 & repneprefx=0)|(repprefx=0 & repneprefx=1))			{ goto inst_start; }
 reptail:	is repprefx=0 & repneprefx=0			{ }
@@ -2349,6 +2362,17 @@ macro fucompe(val1, val2) {
     SF = 0;
 }
 
+macro newpos(pos1, pos2, off) {
+    if (DF == 1) goto <sub>;
+    pos1 = pos1 + off;
+    pos2 = pos2 + off;
+    goto <end>;
+<sub>
+    pos1 = pos1 - off;
+    pos2 = pos2 - off;
+<end>
+}
+
 # The base level constructors
 #   The prefixes
 :^instruction is instrPhase=0 & over=0x2e; instruction     [ segover=1; ]  {} # CS override
@@ -3083,7 +3107,13 @@ define pcodeop clzero;
 :CMP Reg64,rm64     is $(LONGMODE_ON) & vexMode=0 & opsize=2 & byte=0x3b; rm64 & Reg64 ...       { local temp:8 = rm64; subflags(Reg64,temp); local diff = Reg64 - temp; resultflags(diff); }
 @endif
 
-:CMPSB^repe^repetail eseDI1,dseSI1  is vexMode=0 & repe & repetail & byte=0xa6 & dseSI1 & eseDI1        { build repe; build eseDI1; build dseSI1; local temp_DI1:1 = eseDI1; local temp_SI1:1 = dseSI1;  subflags(temp_SI1,temp_DI1); local diff=temp_SI1 - temp_DI1; resultflags(diff); build repetail; }
+define pcodeop memcmp;
+:CMPSB^repx peseDI1,pdseSI1  is vexMode=0 & repx & byte=0xa6 & pdseSI1 & peseDI1
+{
+  off = CX;
+  CX = memcmp(peseDI1,pdseSI1,CX);
+  newpos(DI,SI,off-1);
+}
 :CMPSW^repe^repetail eseDI2,dseSI2  is vexMode=0 & repe & repetail & opsize=0 & byte=0xa7 & dseSI2 & eseDI2 { build repe; build eseDI2; build dseSI2; local temp_DI2:2 = eseDI2; local temp_SI2:2 = dseSI2; subflags(temp_SI2,temp_DI2); local diff=temp_SI2 - temp_DI2; resultflags(diff); build repetail; }
 :CMPSD^repe^repetail eseDI4,dseSI4  is vexMode=0 & repe & repetail & opsize=1 & byte=0xa7 & dseSI4 & eseDI4 { build repe; build eseDI4; build dseSI4; local temp_DI4:4 = eseDI4; local temp_SI4:4 = dseSI4; subflags(temp_SI4,temp_DI4); local diff=temp_SI4 - temp_DI4; resultflags(diff); build repetail; }
 @ifdef IA64
@@ -4107,11 +4137,39 @@ define pcodeop LocalDescriptorTableRegister;
 }
 @endif
 
-:LODSB^rep^reptail dseSI1   is vexMode=0 & rep & reptail & byte=0xAC & dseSI1           { build rep; build dseSI1; AL=dseSI1; build reptail; }
-:LODSW^rep^reptail dseSI2   is vexMode=0 & rep & reptail & opsize=0 & byte=0xAD & dseSI2    { build rep; build dseSI2; AX=dseSI2; build reptail; }
-:LODSD^rep^reptail dseSI4   is vexMode=0 & rep & reptail & opsize=1 & byte=0xAD & dseSI4    { build rep; build dseSI4; EAX=dseSI4; build reptail; }
+define pcodeop memcpy;
+:LODSB dseSI1	is vexMode=0 & repprefx=0 & byte=0xAC & dseSI1	{ AL=dseSI1; SI = SI + 1; }
+:LODSB^repx dseSI1	is vexMode=0 & repx & repprefx=1 & byte=0xAC & dseSI1
+{
+  memcpy(AL, dseSI1, CX);
+  AX = AX + CX;
+  SI = SI + CX;
+}
+:LODSW dseSI2	is vexMode=0 & repprefx=0 & opsize=0 & byte=0xAD & dseSI2  { AX=dseSI2; SI = SI + 2; }
+:LODSW^repx dseSI2	is vexMode=0 & repx & repprefx=1 & opsize=0 & byte=0xAD & dseSI2
+{
+  local tmp = CX * 2;
+  memcpy(AX, dseSI2, CX);
+  AX = AX + tmp;
+  SI = SI + tmp;
+}
+:LODSD dseSI4	is vexMode=0 & repprefx=0 & opsize=1 & byte=0xAD & dseSI4 { EAX=dseSI4; ESI = ESI + 4; }
+:LODSD^repx dseSI4	is vexMode=0 & repx & repprefx=1 & opsize=1 & byte=0xAD & dseSI4
+{
+  local tmp = ECX * 4;
+  memcpy(EAX, dseSI4, ECX);
+  EAX = EAX + tmp;
+  ESI = ESI + tmp;
+}
 @ifdef IA64
-:LODSQ^rep^reptail dseSI8   is $(LONGMODE_ON) & vexMode=0 & rep & reptail & opsize=2 & byte=0xAD & dseSI8    { build rep; build dseSI8; RAX=dseSI8; build reptail; }
+:LODSQ dseSI8	is $(LONGMODE_ON) & vexMode=0 & repprefx=0 & opsize=2 & byte=0xAD & dseSI8 { RAX=dseSI8; RSI = RSI + 8; }
+:LODSQ^repx dseSI8	is $(LONGMODE_ON) & vexMode=0 & repx & repprefx=1 & opsize=2 & byte=0xAD & dseSI8
+{
+  local tmp = RCX * 8;
+  memcpy(RAX, dseSI8, RCX);
+  RAX = RAX + tmp;
+  RSI = RSI + tmp;
+}
 @endif
 
 :LOOP   rel8        is vexMode=0 & addrsize=0 & byte=0xE2; rel8             { CX = CX -1; if (CX!=0) goto rel8; }
@@ -4329,11 +4387,135 @@ define pcodeop swap_bytes;
 :MOVNTI Mem,Reg64       is $(LONGMODE_ON) & vexMode=0 & opsize = 2; byte=0xf; byte=0xc3; Mem & Reg64 ...     { *Mem = Reg64; }
 @endif
 
-:MOVSB^rep^reptail eseDI1,dseSI1    is vexMode=0 & rep & reptail & byte=0xa4 & eseDI1 & dseSI1          { build rep; build eseDI1; build dseSI1; eseDI1 = dseSI1; build reptail; }
-:MOVSW^rep^reptail eseDI2,dseSI2    is vexMode=0 & rep & reptail & opsize=0 & byte=0xa5 & eseDI2 & dseSI2   { build rep; build eseDI2; build dseSI2; eseDI2 = dseSI2; build reptail; }
-:MOVSD^rep^reptail eseDI4,dseSI4    is vexMode=0 & rep & reptail & opsize=1 & byte=0xa5 & eseDI4 & dseSI4   { build rep; build eseDI4; build dseSI4; eseDI4 = dseSI4; build reptail; }
+define pcodeop memmove;
+:MOVSB^repx peseDI1,pdseSI1	is vexMode=0 & repx & repprefx & byte=0xa4 & peseDI1 & pdseSI1
+{
+  local tmp = CX;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 1;
+<code>
+  memmove(peseDI1, pdseSI1, CX);
+  DI = DI + tmp - 1;
+  SI = SI + tmp - 1 ;
+}
+:MOVSB^repx peseDI2,pdseSI2	is vexMode=0 & addrsize=0 & repx & repprefx & byte=0xa4 & peseDI2 & pdseSI2
+{
+  local tmp = CX;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 1;
+<code>
+  memmove(peseDI2, pdseSI2, tmp);
+  DI = DI + tmp - 2;
+  SI = SI + tmp - 2;
+}
+:MOVSB^repx peseDI4,pdseSI4	is vexMode=0 & addrsize=1 & repx & repprefx & byte=0xa4 & peseDI4 & pdseSI4
+{
+  local tmp = ECX;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 1;
+<code>
+  memmove(peseDI4, pdseSI4, tmp);
+  EDI = EDI + tmp - 4;
+  ESI = ESI + tmp - 4;
+}
+@ifdef IA64
+:MOVSB^repx RDI,RSI	is vexMode=0 & addrsize=2 & repx & repprefx & byte=0xa4 & RDI & RSI
+{
+  local tmp = ECX;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 1;
+<code>
+  memmove(RDI, RSI, tmp);
+  RDI = RDI + zext(tmp) - 8;
+  RSI = RSI + zext(tmp) - 8;
+}
+@endif
+
+:MOVSW^repx peseDI2,pdseSI2	is vexMode=0 & addrsize=0 & repx & repprefx & opsize=0 & byte=0xa5 & peseDI2 & pdseSI2
+{
+  local tmp = CX * 2;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 2;
+<code>
+  memmove(peseDI2, pdseSI2, tmp);
+  DI = DI + tmp - 1;
+  SI = SI + tmp - 1;
+}
+:MOVSW^repx peseDI4,pdseSI4	is vexMode=0 & addrsize=1 & repx & repprefx & opsize=0 & byte=0xa5 & peseDI4 & pdseSI4
+{
+
+  local tmp = ECX * 2;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 2;
+<code>
+  memmove(peseDI4, pdseSI4, tmp);
+  EDI = EDI + tmp - 4;
+  ESI = ESI + tmp - 4;
+}
 @ifdef IA64
-:MOVSQ^rep^reptail eseDI8,dseSI8    is $(LONGMODE_ON) & vexMode=0 & rep & reptail & opsize=2 & byte=0xa5 & eseDI8 & dseSI8   { build rep; build eseDI8; build dseSI8; eseDI8 = dseSI8; build reptail; }
+:MOVSW^repx RDI,RSI	is vexMode=0 & addrsize=2 & repx & repprefx & opsize=0 & byte=0xa5 & RDI & RSI
+{
+  local tmp:8 = zext(ECX) * 2;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 2;
+<code>
+  memmove(RDI, RSI, tmp);
+  RDI = RDI + tmp - 8;
+  RSI = RSI + tmp - 8;
+}
+@endif
+:MOVSD^repx peseDI2,pdseSI2	is vexMode=0 & addrsize=0 & repx & repprefx & opsize=1 & byte=0xa5 & peseDI2 & pdseSI2
+{
+  local tmp = CX * 4;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 4;
+<code>
+  memmove(peseDI2, pdseSI2, tmp);
+  DI = DI + tmp - 2;
+  SI = SI + tmp - 2;
+}
+:MOVSD^repx peseDI4,pdseSI4	is vexMode=0 & addrsize=1 & repx & repprefx & opsize=1 & byte=0xa5 & peseDI4 & pdseSI4
+{
+  local tmp = ECX * 4;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 4;
+<code>
+  memmove(peseDI4, pdseSI4, tmp);
+  EDI = EDI + tmp - 4;
+  ESI = ESI + tmp - 4;
+}
+@ifdef IA64
+:MOVSD^repx RDI,RSI	is vexMode=0 & addrsize=2 & repx & repprefx & opsize=1 & byte=0xa5 & RDI & RSI
+{
+  local tmp:8 = zext(ECX) * 4;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 4;
+<code>
+  memmove(RDI, RSI, tmp);
+  RDI = RDI + tmp - 8;
+  RSI = RSI + tmp - 8;
+}
+:MOVSQ^repx RDI,RSI	is $(LONGMODE_ON) & vexMode=0 & addrsize=2 & repx & repprefx & opsize=2 & byte=0xa5 & RDI & RSI
+{
+  local tmp:8 = zext(ECX) * 8;
+  repprefx_:1 = repprefx;
+  if (repprefx_ == 1) goto <code>;
+  tmp = 8;
+<code>
+  memmove(RDI, RSI, tmp);
+  RDI = RDI + tmp - 8;
+  RSI = RSI + tmp - 8;
+}
 @endif
 
 :MOVSX Reg16,rm8    is vexMode=0 & opsize=0 & byte=0xf; byte=0xbe; rm8 & Reg16 ...  { Reg16 = sext(rm8); }
@@ -4832,7 +5014,26 @@ define pcodeop smm_restore_state;
 :SBB  Reg64,rm64       is $(LONGMODE_ON) & vexMode=0 & opsize=2 & byte=0x1b; rm64 & Reg64 ...						{ subCarryFlags( Reg64, rm64 ); resultflags(Reg64); }
 @endif
 
-:SCASB^repe^repetail eseDI1 is vexMode=0 & repe & repetail &            byte=0xae & eseDI1  { build repe; build eseDI1; subflags(AL,eseDI1); local diff=AL-eseDI1; resultflags(diff); build repetail; }
+define pcodeop strchr;
+:SCASB^repe peseDI1 is vexMode=0 & repe & byte=0xae & peseDI1
+{
+  CX = strchr(peseDI1, AL);
+}
+:SCASB^repe peseDI2 is vexMode=0 & addrsize=0 & repe & byte=0xae & peseDI2
+{
+  CX = strchr(peseDI2, AX);
+}
+:SCASB^repe peseDI4 is vexMode=0 & addrsize=1 & repe & byte=0xae & peseDI4
+{
+  ECX = strchr(peseDI4, EAX);
+}
+@ifdef IA64
+:SCASB^repe RDI is vexMode=0 & addrsize=2 & repe & byte=0xae & RDI
+{
+  RCX = strchr(RDI, RAX);
+}
+@endif
+
 :SCASW^repe^repetail eseDI2 is vexMode=0 & repe & repetail & opsize=0 & byte=0xaf & eseDI2  { build repe; build eseDI2; subflags(AX,eseDI2); local diff=AX-eseDI2; resultflags(diff); build repetail; }
 :SCASD^repe^repetail eseDI4 is vexMode=0 & repe & repetail & opsize=1 & byte=0xaf & eseDI4  { build repe; build eseDI4; subflags(EAX,eseDI4); local diff=EAX-eseDI4; resultflags(diff); build repetail; }
 @ifdef IA64
@@ -5000,11 +5201,48 @@ define pcodeop stac;
 
 :STMXCSR m32        is vexMode=0 & byte=0xf; byte=0xae; ( mod != 0b11 & reg_opcode=3 ) ... & m32 { m32 = MXCSR; }
 
-:STOSB^rep^reptail eseDI1   is vexMode=0 & rep & reptail & byte=0xaa & eseDI1           { build rep; build eseDI1; eseDI1=AL; build reptail; }
-:STOSW^rep^reptail eseDI2   is vexMode=0 & rep & reptail & opsize=0 & byte=0xab & eseDI2    { build rep; build eseDI2; eseDI2=AX; build reptail; }
-:STOSD^rep^reptail eseDI4   is vexMode=0 & rep & reptail & opsize=1 & byte=0xab & eseDI4    { build rep; build eseDI4; eseDI4=EAX; build reptail; }
+define pcodeop memset;
+:STOSB^repx peseDI1,AL	is vexMode=0 & repx & byte=0xaa & peseDI1 & AL
+{
+  memset(peseDI1, AL, CX);
+  DI = DI + CX - 1;
+}
+:STOSB^repx peseDI2,AX	is vexMode=0 & addrsize=0 & repx & byte=0xaa & peseDI2 & AX
+{
+  memset(peseDI2, AX, CX);
+  DI = DI + CX - 2;
+}
+:STOSB^repx peseDI4,EAX	is vexMode=0 & addrsize=1 & repx & byte=0xaa & peseDI4 & EAX
+{
+  memset(peseDI4, EAX, ECX);
+  EDI = EDI + ECX - 4;
+}
+@ifdef IA64
+:STOSB^repx eseDI8,RAX   is vexMode=0 & addrsize=2 & repx & byte=0xaa & eseDI8 & RAX
+{
+  memset(RDI, RAX, ECX);
+  RDI = RDI + RCX - 8;
+}
+@endif
+:STOSW^repx peseDI2,AX   is vexMode=0 & repx & opsize=0 & byte=0xab & peseDI2 & AX
+{
+  local tmp = CX * 2;
+  memset(peseDI2, AX, tmp);
+  DI = DI + tmp - 2;
+}
+:STOSD^repx peseDI4,EAX   is vexMode=0 & repx & opsize=1 & byte=0xab & peseDI4 & EAX
+{
+  local tmp = ECX * 4;
+  memset(peseDI4, EAX, tmp);
+  EDI = EDI + tmp - 4;
+}
 @ifdef IA64
-:STOSQ^rep^reptail eseDI8   is $(LONGMODE_ON) & vexMode=0 & rep & reptail & opsize=2 & byte=0xab & eseDI8    { build rep; build eseDI8; eseDI8=RAX; build reptail; }
+:STOSQ^repx peseDI8,RAX   is $(LONGMODE_ON) & vexMode=0 & repx & opsize=2 & byte=0xab & peseDI8 & RAX
+{
+  local tmp = RCX * 8;
+  memset(peseDI8, RAX, tmp);
+  RDI = RDI + tmp - 8;
+}
 @endif
 
 :STR rm16       is vexMode=0 & byte=0xf; byte=0x0; rm16 & reg_opcode=1 ... { rm16 = TaskRegister(); }
diff --git a/Ghidra/Processors/x86/data/languages/lockable.sinc b/Ghidra/Processors/x86/data/languages/lockable.sinc
index 52a28a2ff0..5a66ac5947 100644
--- a/Ghidra/Processors/x86/data/languages/lockable.sinc
+++ b/Ghidra/Processors/x86/data/languages/lockable.sinc
@@ -735,6 +735,14 @@ define pcodeop InterlockedIncrement64;
 }
 @endif
 
+define pcodeop InterlockedExchange;
+define pcodeop InterlockedExchange8;
+define pcodeop InterlockedExchange16;
+:MOV^lockx_ CRmr8,imm8     is vexMode=0 & row=11 & lockx_ & lockprefx & page=0 & CRmr8; imm8
+{
+    InterlockedExchange8(CRmr8:1, imm8:1);
+}
+
 :NEG^lockx m8       is vexMode=0 & lockx & unlock & byte=0xf6; m8 & reg_opcode=3 ...         
 {
     build lockx;
@@ -1033,6 +1041,46 @@ define pcodeop InterlockedIncrement64;
 }
 @endif
 
+:SBB^lockx  Reg8,rm8        is vexMode=0 & lockx & unlock & byte=0x1a; rm8 & Reg8 ...
+{
+    build lockx;
+    build Reg8;
+    subCarryFlags( Reg8, rm8 );
+    resultflags(Reg8);
+    build unlock;
+}
+
+:SBB^lockx  Reg16,rm16       is vexMode=0 & lockx & unlock & opsize=0 & byte=0x1b; rm16 & Reg16 ...
+{
+    build lockx;
+    build Reg16;
+    subCarryFlags( Reg16, rm16 );
+    resultflags(Reg16);
+    build unlock;
+}
+
+:SBB^lockx  Reg32,rm32       is vexMode=0 & lockx & unlock & opsize=1 & byte=0x1b; rm32 & Reg32 ... & check_Reg32_dest ...
+{
+    build lockx;
+    build Reg32;
+    subCarryFlags( Reg32, rm32 );
+    build check_Reg32_dest;
+    resultflags(Reg32);
+    build unlock;
+}
+
+@ifdef IA64
+:SBB^lockx  Reg64,rm64       is $(LONGMODE_ON) & vexMode=0 & lockx & unlock & opsize=2 & byte=0x1b; rm64 & Reg64 ...
+{
+    build lockx;
+    build Reg64;
+    subCarryFlags( Reg64, rm64 );
+    resultflags(Reg64);
+    build unlock;
+}
+@endif
+
+
 :SUB^lockx  m8,imm8     is vexMode=0 & lockx & unlock & $(BYTE_80_82); m8 & reg_opcode=5 ...; imm8     
 {
     build lockx;
@@ -1173,9 +1221,6 @@ define pcodeop InterlockedExchangeAdd64;
 }
 @endif
 
-define pcodeop InterlockedExchange;
-define pcodeop InterlockedExchange8;
-define pcodeop InterlockedExchange16;
 # XCHG with memory operands always asserts a lock signal regardless of prefix presence
 :XCHG^xacq_xrel_prefx^alwaysLock Mem,Reg8	is vexMode=0 & xacq_xrel_prefx & alwaysLock & byte=0x86; Mem & Reg8 ...
 {
-- 
2.45.1

