From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Sleigh-InSPECtor <sleighinspector@outlook.com>
Date: Thu, 16 May 2024 18:15:00 +0930
Subject: [PATCH] 6524: x86: Fix aliasing issues with SIMD instructions

---
 Ghidra/Processors/x86/data/languages/ia.sinc | 26 ++++++++++++--------
 1 file changed, 16 insertions(+), 10 deletions(-)

diff --git a/Ghidra/Processors/x86/data/languages/ia.sinc b/Ghidra/Processors/x86/data/languages/ia.sinc
index fce3684129..319493b27b 100644
--- a/Ghidra/Processors/x86/data/languages/ia.sinc
+++ b/Ghidra/Processors/x86/data/languages/ia.sinc
@@ -5099,8 +5099,9 @@ CMPSS_OPERAND: ", "^imm8 is imm8   { }
 
 :CVTDQ2PD     XmmReg1, XmmReg2  is vexMode=0 &  $(PRE_F3) & byte=0x0F; byte=0xE6; xmmmod=3 & XmmReg1 & XmmReg2
 {
-    XmmReg1[0,64] = int2float( XmmReg2[0,32] );
-    XmmReg1[64,64] = int2float( XmmReg2[32,32] );
+    local tmp:8 = XmmReg2[0,64];
+    XmmReg1[0,64] = int2float( tmp[0,32] );
+    XmmReg1[64,64] = int2float( tmp[32,32] );
 }
 
 :CVTDQ2PS     XmmReg, m128      is vexMode=0 &  mandover=0 & byte=0x0F; byte=0x5B; m128 & XmmReg ...
@@ -5219,8 +5220,9 @@ CMPSS_OPERAND: ", "^imm8 is imm8   { }
 
 :CVTPS2PD     XmmReg1, XmmReg2  is vexMode=0 &  mandover=0 & byte=0x0F; byte=0x5A; xmmmod=3 & XmmReg1 & XmmReg2
 {
-    XmmReg1[0,64] = float2float( XmmReg2[0,32] );
-    XmmReg1[64,64] = float2float( XmmReg2[32,32] );
+    local tmp:8 = XmmReg2[0,64];
+    XmmReg1[0,64] = float2float( tmp[0,32] );
+    XmmReg1[64,64] = float2float( tmp[32,32] );
 }
 
 :CVTPS2PI     mmxreg, m64         is vexMode=0 &  mandover=0 & byte=0x0F; byte=0x2D; mmxreg ... & m64
@@ -5473,8 +5475,9 @@ define pcodeop divps;
 
 :HADDPD        XmmReg1, XmmReg2    is vexMode=0 &  $(PRE_66) & byte=0x0F; byte=0x7C; xmmmod=3 & XmmReg1 & XmmReg2
 {
+    local tmp:16 = XmmReg2;
     XmmReg1[0,64] = XmmReg1[0,64] f+ XmmReg1[64,64];
-    XmmReg1[64,64] = XmmReg2[0,64] f+ XmmReg2[64,64];
+    XmmReg1[64,64] = tmp[0,64] f+ tmp[64,64];
 }
 
 :HADDPS        XmmReg, m128        is vexMode=0 &  $(PRE_F2) & byte=0x0F; byte=0x7C; m128 & XmmReg ...
@@ -5488,10 +5491,11 @@ define pcodeop divps;
 
 :HADDPS        XmmReg1, XmmReg2    is vexMode=0 &  $(PRE_F2) & byte=0x0F; byte=0x7C; xmmmod=3 & XmmReg1 & XmmReg2
 {
+    local tmp:16 = XmmReg2;
     XmmReg1[0,32] = XmmReg1[0,32] f+ XmmReg1[32,32];
     XmmReg1[32,32] = XmmReg1[64,32] f+ XmmReg1[96,32];
-    XmmReg1[64,32] = XmmReg2[0,32] f+ XmmReg2[32,32];
-    XmmReg1[96,32] = XmmReg2[64,32] f+ XmmReg2[96,32];
+    XmmReg1[64,32] = tmp[0,32] f+ tmp[32,32];
+    XmmReg1[96,32] = tmp[64,32] f+ tmp[96,32];
 }
 
 :HSUBPD        XmmReg, m128        is vexMode=0 &  $(PRE_66) & byte=0x0F; byte=0x7D; m128 & XmmReg ...
@@ -5503,8 +5507,9 @@ define pcodeop divps;
 
 :HSUBPD        XmmReg1, XmmReg2    is vexMode=0 &  $(PRE_66) & byte=0x0F; byte=0x7D; xmmmod=3 & XmmReg1 & XmmReg2
 {
+    local tmp:16 = XmmReg2;
     XmmReg1[0,64] = XmmReg1[0,64] f- XmmReg1[64,64];
-    XmmReg1[64,64] = XmmReg2[0,64] f- XmmReg2[64,64];
+    XmmReg1[64,64] = tmp[0,64] f- tmp[64,64];
 }
 
 :HSUBPS        XmmReg, m128        is vexMode=0 &  $(PRE_F2) & byte=0x0F; byte=0x7D; m128 & XmmReg ...
@@ -5518,10 +5523,11 @@ define pcodeop divps;
 
 :HSUBPS        XmmReg1, XmmReg2    is vexMode=0 &  $(PRE_F2) & byte=0x0F; byte=0x7D; xmmmod=3 & XmmReg1 & XmmReg2
 {
+    local tmp:16 = XmmReg2;
     XmmReg1[0,32] = XmmReg1[0,32] f- XmmReg1[32,32];
     XmmReg1[32,32] = XmmReg1[64,32] f- XmmReg1[96,32];
-    XmmReg1[64,32] = XmmReg2[0,32] f- XmmReg2[32,32];
-    XmmReg1[96,32] = XmmReg2[64,32] f- XmmReg2[96,32];
+    XmmReg1[64,32] = tmp[0,32] f- tmp[32,32];
+    XmmReg1[96,32] = tmp[64,32] f- tmp[96,32];
 }
 
 #--------------------
-- 
2.45.0

